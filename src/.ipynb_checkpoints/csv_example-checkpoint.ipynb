{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f730a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203614d2-2136-4743-b334-1ef199aa6a52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import scipy as sp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3718c73-c886-4cfd-a292-6b6960648e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In fact, we use the pd.datetime \n",
    "import datetime \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4021fe5e-5f26-4eed-bafe-5b439a2d1102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class company():\n",
    "    # Timeformat, pd datetime, convenient to use with the datetime array. \n",
    "    start = pd.to_datetime('1970-01-01',format='%Y-%m-%d')\n",
    "    end = pd.to_datetime('2023-11-21',format='%Y-%m-%d')\n",
    "    frequency = pd.Timedelta(days=1) \n",
    "    \n",
    "    # We need the ticker name of the company to get started \n",
    "    def __init__(self,ticker,autofill=True):\n",
    "        self.ticker = ticker  \n",
    "        self.constrain_time_range()\n",
    "        self.generate_time_series()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.ticker\n",
    "    def __str__(self):\n",
    "        return \"Company Class :{}\".format(self.ticker)\n",
    " \n",
    "    # Start \"%Y-%m-%d\" , End \"%Y-%m-%d\" , Frequency N days. \n",
    "    def update_time_range(self,start,end,frequency) : \n",
    "        self.start = pd.to_datetime(start,format='%Y-%m-%d')\n",
    "        self.end = pd.to_datetime(end,format='%Y-%m-%d')\n",
    "        self.frequency = pd.Timedelta(days=frequency)\n",
    "        self.constrain_time_range()\n",
    "        self.generate_time_series()\n",
    "\n",
    "        \n",
    "    def constrain_time_range(self):\n",
    "        # The temp is to save the readout data \n",
    "        temp = pd.read_csv('../data/price/{}_price.csv'.format(self.ticker))\n",
    "        \n",
    "        # Filter the data within the interesting time  area. \n",
    "        referdate = pd.to_datetime( temp['Date'], format='%Y-%m-%d') \n",
    "        \n",
    "        price_start = np.min(np.array(referdate)) \n",
    "        price_end = np.max(np.array(referdate)) \n",
    "        \n",
    "        if self.start < price_start : \n",
    "            self.start = price_start \n",
    "        \n",
    "        if self.end > price_end : \n",
    "            self.end = price_end \n",
    "\n",
    "        \n",
    "    def generate_time_series(self): \n",
    "        data_points_number = int((self.end - self.start)/(self.frequency)) +1 \n",
    "        self.time_series = np.array([ x*self.frequency + self.start for x in range(data_points_number) ])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # To verify the integrity of the data .... \n",
    "    def feature_list(self): \n",
    "        pass \n",
    "    \n",
    "    def print_feature_list(self):\n",
    "        pass \n",
    "    \n",
    "    def check_data(self):\n",
    "        pass \n",
    "\n",
    "\n",
    "    def read_data(self,target_list):\n",
    "        query_result = np.zeros((len(target_list), len(self.time_series) ))\n",
    "        if len(target_list) == 1 : \n",
    "            # the 2d numpy array (1,n) behaves quite strange \n",
    "            query_result = self.read_single_data(target_list[0])\n",
    "        else :\n",
    "            for i in range(len(target_list)):\n",
    "                query_result[i]= self.read_single_data(target_list[i])\n",
    "        \n",
    "        return (self.time_series,query_result)\n",
    "    \n",
    "    def read_single_data(self,target):\n",
    "        if target[0]=='price':\n",
    "            return self.read_single_price_data(target)\n",
    "        elif target[0]=='balance' : \n",
    "            return self.read_single_balance_data(target)\n",
    "        elif target[0]=='cashflow' : \n",
    "            return self.read_single_cashflow_data(target)\n",
    "        elif target[0]=='esg' : \n",
    "            return self.read_single_esg_data(target)\n",
    "        elif target[0]=='financials':\n",
    "            return self.read_single_financials_data(target)\n",
    "        elif target[0]=='valuation':\n",
    "            return self.read_single_valuation_data(target)\n",
    "        else : \n",
    "            print(\"Warning, make sure that you type the right feature name\")\n",
    "    \n",
    "    def read_single_price_data(self,target):\n",
    "        # The temp is to save the readout data \n",
    "        temp = pd.read_csv('../data/price/{}_price.csv'.format(self.ticker))\n",
    "        \n",
    "        # Filter the data within the interesting time  area. \n",
    "        referdate = pd.to_datetime( temp['Date'], format='%Y-%m-%d') \n",
    "        temp_date = referdate[ np.array( (referdate <= self.end) &  (referdate >= self.start) )]\n",
    "        temp_data = np.array(temp[target[1]][ np.array( (referdate <= self.end) &  (referdate >= self.start) )])\n",
    "        \n",
    "        # Not Every data works, and then we will rebuild the data according to the the time series \n",
    "        # For the timebeing, we will use the uniform choice method \n",
    "        return_args = np.array( np.arange(len(self.time_series))* len(temp_date) / len(self.time_series) ).astype(int)\n",
    "        return_data = np.array(temp_data[return_args])\n",
    "        \n",
    "        return return_data\n",
    "\n",
    "    \n",
    "    def read_single_balance_data(self,target):\n",
    "        temp = pd.read_csv('../data/balance/{}_balance.csv'.format(self.ticker))\n",
    "        \n",
    "        row_name = temp['name']\n",
    "        n_row = len(row_name)\n",
    "        target_row = 0 \n",
    "        \n",
    "        # find the columns we want \n",
    "        for i in range(n_row):\n",
    "            if row_name[i].strip() == target[1] : \n",
    "                target_row = i \n",
    "                break \n",
    "        \n",
    "        # Filter the data within the \n",
    "        referdate = pd.to_datetime( np.array(temp.columns[1:]) ,format='%m/%d/%Y' )\n",
    "        temp_date= referdate[ np.array( (referdate <= self.end) &  (referdate >= self.start) )]\n",
    "        temp_data= np.array(temp.iloc[i][1:][ np.array( (referdate <= self.end) &  (referdate >= self.start) )])\n",
    "        \n",
    "        # Not Every data works, and then we will rebuild the data according to the the time series \n",
    "        # For the timebeing, we will use the uniform choice method \n",
    "        return_args = np.array( np.arange(len(self.time_series))* len(temp_date) / len(self.time_series) ).astype(int)\n",
    "        return_data = np.array(temp_data[return_args])\n",
    "        return_data = [ float(i.replace(',','')) for i in return_data ]\n",
    "        return return_data\n",
    "    \n",
    "    def read_single_cashflow_data(self,target):\n",
    "        temp = pd.read_csv('../data/cashflow/{}_cashflow.csv'.format(self.ticker))\n",
    "        \n",
    "        row_name = temp['name']\n",
    "        n_row = len(row_name)\n",
    "        target_row = 0 \n",
    "        \n",
    "        # find the columns we want \n",
    "        for i in range(n_row):\n",
    "            if row_name[i].strip() == target[1] : \n",
    "                target_row = i \n",
    "                break \n",
    "        \n",
    "        # Filter the data within the \n",
    "        referdate = pd.to_datetime( np.array(temp.columns[2:]) ,format='%m/%d/%Y' )\n",
    "        temp_date= referdate[ np.array( (referdate <= self.end) &  (referdate >= self.start) )]\n",
    "        temp_data= np.array(temp.iloc[i][2:][ np.array( (referdate <= self.end) &  (referdate >= self.start) )])\n",
    "        \n",
    "        # Not Every data works, and then we will rebuild the data according to the the time series \n",
    "        # For the timebeing, we will use the uniform choice method \n",
    "        return_args = np.array( np.arange(len(self.time_series))* len(temp_date) / len(self.time_series) ).astype(int)\n",
    "        return_data = np.array(temp_data[return_args])     \n",
    "        return_data = [ float(i.replace(',','')) for i in return_data ]\n",
    "        return return_data \n",
    " \n",
    "    \n",
    "    def read_single_financials_data(self,target):\n",
    "        temp = pd.read_csv('../data/financials/{}_financials.csv'.format(self.ticker))\n",
    "        \n",
    "        row_name = temp['name']\n",
    "        n_row = len(row_name)\n",
    "        target_row = 0 \n",
    "        \n",
    "        # find the columns we want \n",
    "        for i in range(n_row):\n",
    "            if row_name[i].strip() == target[1] : \n",
    "                target_row = i \n",
    "                break \n",
    "        \n",
    "        # Filter the data within the \n",
    "        referdate = pd.to_datetime( np.array(temp.columns[2:]) ,format='%m/%d/%Y' )\n",
    "        temp_date= referdate[ np.array( (referdate <= self.end) &  (referdate >= self.start) )]\n",
    "        temp_data= np.array(temp.iloc[i][2:][ np.array( (referdate <= self.end) &  (referdate >= self.start) )])\n",
    "        \n",
    "        # Not Every data works, and then we will rebuild the data according to the the time series \n",
    "        # For the timebeing, we will use the uniform choice method \n",
    "        return_args = np.array( np.arange(len(self.time_series))* len(temp_date) / len(self.time_series) ).astype(int)\n",
    "        return_data = np.array(temp_data[return_args])     \n",
    "        return_data = [ float(i.replace(',','')) for i in return_data ]\n",
    "        return return_data  \n",
    "    \n",
    "    def read_single_valuation_data(self,target):\n",
    "        temp = pd.read_csv('../data/valuation/{}_valuation.csv'.format(self.ticker))\n",
    "        \n",
    "        row_name = temp['name']\n",
    "        n_row = len(row_name)\n",
    "        target_row = 0 \n",
    "        \n",
    "        # find the columns we want \n",
    "        for i in range(n_row):\n",
    "            if row_name[i].strip() == target[1] : \n",
    "                target_row = i \n",
    "                break \n",
    "        \n",
    "        # Filter the data within the time range \n",
    "        referdate = pd.to_datetime( np.array(temp.columns[2:]) ,format='%m/%d/%Y' )\n",
    "        temp_date= referdate[ np.array( (referdate <= self.end) &  (referdate >= self.start) )]\n",
    "        temp_data= np.array(temp.iloc[i][2:][ np.array( (referdate <= self.end) &  (referdate >= self.start) )])\n",
    "        \n",
    "        # Not Every data works, and then we will rebuild the data according to the the time series \n",
    "        # For the timebeing, we will use the uniform choice method \n",
    "        return_args = np.array( np.arange(len(self.time_series))* len(temp_date) / len(self.time_series) ).astype(int)\n",
    "        return_data = np.array(temp_data[return_args])     \n",
    "        return_data = [ float(i.replace(',','')) for i in return_data ]\n",
    "        return return_data  \n",
    "\n",
    "    \n",
    "    \n",
    "    def read_single_esg_data(self,target):\n",
    "        temp = pd.read_csv('../data/esg/{}_esg.csv'.format(self.ticker))        \n",
    "        target_row = np.where(np.array(temp['aspectname'])== target[1])[0]\n",
    "        \n",
    "        # Filter data \n",
    "        referdate = pd.to_datetime( np.array(temp.iloc[target_row]['scoredate']) ,format='%Y-%m-%d' )\n",
    "        temp_date= referdate[ np.array( (referdate <= self.end) &  (referdate >= self.start) )]\n",
    "        temp_data= np.array(temp.iloc[target_row]['scorevalue'][ np.array( (referdate <= self.end) &  (referdate >= self.start) )])\n",
    "        \n",
    "        # Not Every data works, and then we will rebuild the data according to the the time series \n",
    "        # For the timebeing, we will use the uniform choice method \n",
    "        return_args = np.array( np.arange(len(self.time_series))* len(temp_date) / len(self.time_series) ).astype(int)\n",
    "        return_data = np.array(temp_data[return_args])     \n",
    "        return return_data \n",
    "    \n",
    "    def plot_single_data(self,target):\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13d7ca3e-bade-43b8-b5b1-761a68c85b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14938\n"
     ]
    }
   ],
   "source": [
    "start_run_time = datetime.datetime.now() \n",
    "a= company('AAPL')\n",
    "a.update_time_range('1970-01-01','2023-11-21',1)\n",
    "x= a.read_data([('price','Close'),('balance','CurrentAssets'),('esg','S&P Global ESG Score')])\n",
    "end_run_time = datetime.datetime.now() \n",
    "print(len(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ad92d181-09a8-4e04-968b-1a6e3b7f43a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 124, 247, 378, 509, 638, 767, 889])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "94aa2098-4873-401e-928a-5d1266a7af19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# The temp is to save the readout data \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m temp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/price/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_price.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mticker))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Filter the data within the interesting time  area. \u001b[39;00m\n\u001b[1;32m      5\u001b[0m referdate \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime( temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "        # The temp is to save the readout data \n",
    "        temp = pd.read_csv('../data/price/{}_price.csv'.format(self.ticker))\n",
    "        \n",
    "        # Filter the data within the interesting time  area. \n",
    "        referdate = pd.to_datetime( temp['Date'], format='%Y-%m-%d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ff2de3cb-fcde-475d-a0a3-6b3355b0d498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp = pd.read_csv('../data/price/{}_price.csv'.format(\"AAPL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "817237b1-6709-4dba-aef1-9930412eea51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "referdate = pd.to_datetime( temp['Date'], format='%Y-%m-%d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1d4c8496-576c-4444-9009-c8e4cf331a77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(np.array(referdate)) < referdate[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "97ba1126-523e-4694-bc45-225c339db608",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       0.0\n",
       "124     0.0\n",
       "247     0.0\n",
       "378     0.0\n",
       "509    90.0\n",
       "638    90.0\n",
       "767    90.0\n",
       "889    90.0\n",
       "Name: scorevalue, dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.iloc[target_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4d48f31a-84da-4d5b-839c-3acdcc832414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mint\u001b[39m(x\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "int(x.replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "259a7c92-d1d1-4385-a2d5-beae71643837",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string operation on non-string array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39mchar\u001b[38;5;241m.\u001b[39mreplace(x,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mreplace\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/defchararray.py:1265\u001b[0m, in \u001b[0;36mreplace\u001b[0;34m(a, old, new, count)\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_replace_dispatcher)\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplace\u001b[39m(a, old, new, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;124;03m    For each element in `a`, return a copy of the string with all\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;124;03m    occurrences of substring `old` replaced by `new`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;124;03m    array(['The dwash was fresh', 'Thwas was it'], dtype='<U19')\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _to_string_or_unicode_array(\n\u001b[0;32m-> 1265\u001b[0m         _vec_string(\n\u001b[1;32m   1266\u001b[0m             a, object_, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m'\u001b[39m, [old, new] \u001b[38;5;241m+\u001b[39m _clean_args(count)))\n",
      "\u001b[0;31mTypeError\u001b[0m: string operation on non-string array"
     ]
    }
   ],
   "source": [
    "np.char.replace(x,',','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "afb857da-1c53-4f1f-9301-6faa9aadc23b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '122,659,000,000'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a\u001b[38;5;241m.\u001b[39mread_single_data((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalance\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCurrentAssets\u001b[39m\u001b[38;5;124m'\u001b[39m))\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '122,659,000,000'"
     ]
    }
   ],
   "source": [
    "a.read_single_data(('balance','CurrentAssets')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0a47e50e-0c04-4385-834b-efeea665c7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([('price','Close'),('balance','CurrentAssets')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb36e47-e71a-44ab-8f01-29fd1a7c7e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "513544c1-d3eb-4d46-b4d8-2e2398e9d51f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      2013-09-12\n",
       "124    2013-09-12\n",
       "247    2014-09-11\n",
       "378    2014-09-11\n",
       "509    2015-09-10\n",
       "638    2015-09-10\n",
       "767    2016-09-08\n",
       "889    2016-09-08\n",
       "Name: scoredate, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv(\"../data/esg/A_esg.csv\")\n",
    "temp.iloc[x]['scoredate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "79eb14f8-4e7a-4fd7-ab53-edb41fb4b1e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "institutionid                       4075849\n",
       "scoredate                        2013-09-12\n",
       "scoretype              S&P Global ESG Score\n",
       "aspectname             S&P Global ESG Score\n",
       "scorevalue                             61.0\n",
       "ticker                                    A\n",
       "companyname      Agilent Technologies, Inc.\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "01b00d82-df31-4f1a-804f-aebdf8cc9606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_row = np.where(np.array(temp['aspectname'])== 'Climate Change Governance')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6945a3fa-ec1c-43cb-bec8-0c776bb7b75b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2013-09-12 00:00:00')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime( np.array(temp.iloc[target_row]['scoredate']) ,format='%Y-%m-%d' )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4c1a6e23-9742-427a-aa4d-4b59c2234713",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2013-09-12', '2013-09-12', '2014-09-11', '2014-09-11',\n",
       "       '2015-09-10', '2015-09-10', '2016-09-08', '2016-09-08'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(temp.iloc[target_row]['scoredate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eaf9694b-4aa6-4529-b7fc-81893f61cfc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2023-07-31', '2023-04-30', '2023-01-31', '2022-10-31',\n",
       "               '2022-07-31', '2022-04-30', '2022-01-31', '2021-10-31',\n",
       "               '2021-07-31', '2021-04-30', '2021-01-31', '2020-10-31',\n",
       "               '2020-07-31', '2020-04-30', '2020-01-31', '2019-10-31',\n",
       "               '2019-07-31', '2019-04-30', '2019-01-31', '2018-10-31',\n",
       "               '2018-07-31', '2018-04-30', '2018-01-31', '2017-10-31',\n",
       "               '2017-07-31', '2017-04-30', '2017-01-31', '2016-10-31',\n",
       "               '2016-07-31', '2016-04-30', '2016-01-31', '2015-10-31',\n",
       "               '2015-07-31', '2015-04-30', '2015-01-31', '2014-10-31',\n",
       "               '2014-07-31', '2014-04-30', '2014-01-31', '2013-10-31',\n",
       "               '2013-07-31', '2013-04-30', '2013-01-31', '2012-10-31',\n",
       "               '2012-07-31', '2012-04-30', '2012-01-31', '2011-10-31',\n",
       "               '2011-07-31', '2011-04-30', '2011-01-31', '2010-10-31',\n",
       "               '2010-07-31', '2010-04-30', '2010-01-31', '2009-10-31',\n",
       "               '2009-07-31', '2009-04-30', '2009-01-31', '2008-10-31',\n",
       "               '2008-07-31', '2008-04-30', '2008-01-31', '2007-10-31',\n",
       "               '2007-07-31', '2007-04-30', '2007-01-31', '2006-10-31',\n",
       "               '2006-07-31', '2006-04-30', '2006-01-31', '2005-10-31',\n",
       "               '2005-07-31', '2005-04-30', '2005-01-31', '2004-10-31',\n",
       "               '2004-07-31', '2004-04-30', '2004-01-31', '2003-10-31',\n",
       "               '2003-07-31', '2003-04-30', '2003-01-31', '2002-10-31',\n",
       "               '2002-07-31', '2002-04-30', '2002-01-31', '2001-10-31',\n",
       "               '2001-07-31', '2001-04-30', '2001-01-31', '2000-10-31',\n",
       "               '2000-07-31', '2000-04-30', '2000-01-31'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " pd.to_datetime( np.array(temp.columns[2:]) ,format='%m/%d/%Y' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "664af613-265f-4551-9fa4-be6e4db32479",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mto_datetime( temp\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m1\u001b[39m:] , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1121\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         result \u001b[38;5;241m=\u001b[39m _convert_and_box_cache(arg, cache_array, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1121\u001b[0m         result \u001b[38;5;241m=\u001b[39m convert_listlike(arg, \u001b[38;5;28mformat\u001b[39m, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1122\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(arg):\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1124\u001b[0m         \u001b[38;5;66;03m# error: Argument 1 to \"_maybe_cache\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m         \u001b[38;5;66;03m# \"Union[float, str, datetime, List[Any], Tuple[Any, ...], ExtensionArray,\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m         \u001b[38;5;66;03m# ndarray[Any, Any], Series]\"; expected \"Union[List[Any], Tuple[Any, ...],\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m         \u001b[38;5;66;03m# Union[Union[ExtensionArray, ndarray[Any, Any]], Index, Series], Series]\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:488\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[1;32m    490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[1;32m    491\u001b[0m     arg,\n\u001b[1;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m )\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:519\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    509\u001b[0m     arg,\n\u001b[1;32m    510\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    514\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m array_strptime(arg, fmt, exact\u001b[38;5;241m=\u001b[39mexact, errors\u001b[38;5;241m=\u001b[39merrors, utc\u001b[38;5;241m=\u001b[39mutc)\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[0;32mstrptime.pyx:195\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pd.to_datetime( temp.columns[1:] , '%m/%d/%Y' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "311cc22c-cda4-4f17-aec7-5c051ed51ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pd\u001b[38;5;241m.\u001b[39mto_datetime( np\u001b[38;5;241m.\u001b[39marray(temp\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m1\u001b[39m:]) , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1144\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         result \u001b[38;5;241m=\u001b[39m _convert_and_box_cache(argc, cache_array)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1144\u001b[0m         result \u001b[38;5;241m=\u001b[39m convert_listlike(argc, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1146\u001b[0m     result \u001b[38;5;241m=\u001b[39m convert_listlike(np\u001b[38;5;241m.\u001b[39marray([arg]), \u001b[38;5;28mformat\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:488\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[1;32m    490\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64ns(\n\u001b[1;32m    491\u001b[0m     arg,\n\u001b[1;32m    492\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    496\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m )\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:519\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    509\u001b[0m     arg,\n\u001b[1;32m    510\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    514\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    515\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    516\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 519\u001b[0m     result, timezones \u001b[38;5;241m=\u001b[39m array_strptime(arg, fmt, exact\u001b[38;5;241m=\u001b[39mexact, errors\u001b[38;5;241m=\u001b[39merrors, utc\u001b[38;5;241m=\u001b[39mutc)\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tz \u001b[38;5;129;01min\u001b[39;00m timezones):\n\u001b[1;32m    521\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[0;32mstrptime.pyx:195\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pd.to_datetime( np.array(temp.columns[1:]) , '%m/%d/%Y' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83f1e59b-2c69-4a4d-8e8c-87f369758ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime64' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39marray(temp\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m1\u001b[39m:])\u001b[38;5;241m.\u001b[39mastype(datetime64)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime64' is not defined"
     ]
    }
   ],
   "source": [
    "np.array(temp.columns[1:]).astype(datetime64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df165528-b9a1-4d41-ab96-7db5e4b3d3ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['07/31/2023', '04/30/2023', '01/31/2023', '10/31/2022',\n",
       "       '07/31/2022', '04/30/2022', '01/31/2022', '10/31/2021',\n",
       "       '07/31/2021', '04/30/2021', '01/31/2021', '10/31/2020',\n",
       "       '07/31/2020', '04/30/2020', '01/31/2020', '10/31/2019',\n",
       "       '07/31/2019', '04/30/2019', '01/31/2019', '10/31/2018',\n",
       "       '07/31/2018', '04/30/2018', '01/31/2018', '10/31/2017',\n",
       "       '07/31/2017', '04/30/2017', '01/31/2017', '10/31/2016',\n",
       "       '07/31/2016', '04/30/2016', '01/31/2016', '10/31/2015',\n",
       "       '07/31/2015', '04/30/2015', '01/31/2015', '10/31/2014',\n",
       "       '07/31/2014', '04/30/2014', '01/31/2014', '10/31/2013',\n",
       "       '07/31/2013', '04/30/2013', '01/31/2013', '10/31/2012',\n",
       "       '07/31/2012', '04/30/2012', '01/31/2012', '10/31/2011',\n",
       "       '07/31/2011', '04/30/2011', '01/31/2011', '10/31/2010',\n",
       "       '07/31/2010', '04/30/2010', '01/31/2010', '10/31/2009',\n",
       "       '07/31/2009', '04/30/2009', '01/31/2009', '10/31/2008',\n",
       "       '07/31/2008', '04/30/2008', '01/31/2008', '10/31/2007',\n",
       "       '07/31/2007', '04/30/2007', '01/31/2007', '10/31/2006',\n",
       "       '07/31/2006', '04/30/2006', '01/31/2006', '10/31/2005',\n",
       "       '07/31/2005', '04/30/2005', '01/31/2005', '10/31/2004',\n",
       "       '07/31/2004', '04/30/2004', '01/31/2004', '10/31/2003',\n",
       "       '07/31/2003', '04/30/2003', '01/31/2003', '10/31/2002',\n",
       "       '07/31/2002', '04/30/2002', '01/31/2002', '10/31/2001',\n",
       "       '07/31/2001', '04/30/2001', '01/31/2001', '10/31/2000',\n",
       "       '07/31/2000', '04/30/2000', '01/31/2000', '10/31/1999'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(temp.columns[1:]).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c538b03b-4ad7-45e5-a6e1-b91191326dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     07/31/2023\n",
       "1     04/30/2023\n",
       "2     01/31/2023\n",
       "3     10/31/2022\n",
       "4     07/31/2022\n",
       "         ...    \n",
       "91    10/31/2000\n",
       "92    07/31/2000\n",
       "93    04/30/2000\n",
       "94    01/31/2000\n",
       "95    10/31/1999\n",
       "Name: 0, Length: 96, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(temp.columns[1:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44d70895-ff93-4446-bc6a-847c24789e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-07-31 00:00:00')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime( np.array(temp.columns[1:]) ,format='%m/%d/%Y' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45bf17f5-d602-487d-8d00-d42f5d23545c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TotalAssets'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['name'][0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9f1a8708-8920-47b7-98b4-7996a05e77c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_list=[('price','Close')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bdc99e2e-7569-44c2-b1e6-4ccf68bb644e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_result = np.zeros((len(target_list), len(a.time_series) )).reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "14ad95dd-dddd-4b5e-8dc0-ff1a12eb9563",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 19683)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1bc4cda-c6b9-4312-a41f-aa4be1d748be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b35cf1e-0213-4b3d-9bf5-c90b101248e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(8)[(np.arange(14) * 8 / 14).astype(int)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5505d8df-0476-47ce-a706-b6ebe0a9cc14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1982-11-30', '1982-12-01', '1982-12-02', ..., '2023-10-19',\n",
       "       '2023-10-20', '2023-10-23'], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(a_temp['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9e676c5e-7c96-431e-91ad-98d7b235a286",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 19682)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.start + range( int((a.end - a.start ) / pd.Timedelta(days=1)) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe2a8702-d59f-4927-9b50-38a1df29c24c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = pd.read_csv(\"../data/price/AAPL_price.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d9840a-adb3-4b5d-be9f-9fe07c978e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b97da657-2f76-4a0c-8283-1986359e8ed4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a['Date']= pd.to_datetime(a['Date'],format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1d51fe8f-65a4-4b55-a3f9-8843c19a3825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b =pd.to_datetime(a_temp['Date'],format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ec8bfc9f-971d-498f-b781-9d9a8f77e757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c= b + pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e9f5d341-fd63-4274-8aec-7a109eda891f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "         ... \n",
       "10305    True\n",
       "10306    True\n",
       "10307    True\n",
       "10308    True\n",
       "10309    True\n",
       "Name: Date, Length: 10310, dtype: bool"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6b739e75-ff8a-4b69-97a5-8159ca8f5f8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1 days\n",
       "1       1 days\n",
       "2       1 days\n",
       "3       1 days\n",
       "4       1 days\n",
       "         ...  \n",
       "10305   1 days\n",
       "10306   1 days\n",
       "10307   1 days\n",
       "10308   1 days\n",
       "10309   1 days\n",
       "Name: Date, Length: 10310, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c -b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "96308333-226a-4871-b14f-32e7c70d5d2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1970-01-02 00:00:00')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime('1970-01-01',format='%Y-%m-%d') + pd.Timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ae58454d-c4df-47d2-8854-1e5e4b781825",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1982-11-30 00:00:00')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Timestamp(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3bd09943-4e5e-4626-826d-720b97df21a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.datetime64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m datetime\u001b[38;5;241m.\u001b[39mdatetime(np\u001b[38;5;241m.\u001b[39marray(b)[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.datetime64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "datetime.datetime(np.array(b)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f024d01b-1f5c-43e3-b55b-610ff3138f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Timestamp' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mfromtimestamp(b[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Timestamp' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "datetime.datetime.fromtimestamp(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bae5f2dd-0aa4-421c-9910-0d56ce57740b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39marray(pd\u001b[38;5;241m.\u001b[39mto_datetime(a_temp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]))\u001b[38;5;241m.\u001b[39mdate()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'date'"
     ]
    }
   ],
   "source": [
    "np.array(pd.to_datetime(a_temp['Date']) , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c41ee23-18ea-43c0-9fa7-6ea908e52dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# datetime.strptime() : From string to datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "834182c3-8a2e-4c9f-8bf8-4d528e3284bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "converted_date = datetime.datetime.strptime(np.array(a['Date'])[0],'%Y-%m-%d').date()\n",
    "# %Y four digit year , %m two digit month , %d two digit date\n",
    "\n",
    "added_date = converted_date + datetime.timedelta(days=1)\n",
    "# add time \n",
    "\n",
    "\n",
    "# Calculate the time difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e18a070-c76c-4397-b6fe-c4ae97b9dfff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(1982, 12, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe3664d-fcf6-4e06-b069-9e20913f9fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
